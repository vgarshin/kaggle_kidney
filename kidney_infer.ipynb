{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tifffile as tiff\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet, FPN, Linknet\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from tqdm import tqdm\n",
    "print('tensorflow version:', tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "KAGGLE = False\n",
    "MDLS_FOLDS = {'v39': [4], 'v46': [1, 2]}\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/hubmap-kidney-segmentation'\n",
    "    MDLS_PATHS = {ver: f'../input/kidney-models-{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "else:\n",
    "    DATA_PATH = './data2'\n",
    "    MDLS_PATHS = {ver: f'./models_{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "THRESHOLD = .4\n",
    "VOTERS = 1\n",
    "TTAS = [0, 1, 2, 3]\n",
    "EXPAND = 4\n",
    "MIN_OVERLAP = 256\n",
    "IDNT = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "STRATEGY = tf.distribute.get_strategy() \n",
    "SUB_PATH = f'{DATA_PATH}/test' if TEST else f'{DATA_PATH}/train'\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "for ver, _ in MDLS_FOLDS.items():\n",
    "    with open(f'{MDLS_PATHS[ver]}/params.json') as file:\n",
    "        params_dict[ver] = json.load(file)\n",
    "for ver, params in params_dict.items():\n",
    "    print('version:', ver, '| loaded params:', params_dict, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    return (1 - dice_coef(y_true, y_pred, smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return params['bce_weight'] * binary_crossentropy(y_true, y_pred) + \\\n",
    "        (1 - params['bce_weight']) * dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, input_shape, path, \n",
    "              loss_type='bce_dice', umodel='unet', \n",
    "              classes=1, lr=.001):\n",
    "    if backbone == 'efficientnetb0':\n",
    "        weights = f'{path}/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb1':\n",
    "        weights = f'{path}/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb2':\n",
    "        weights = f'{path}/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb3':\n",
    "        weights = f'{path}/efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'resnet34':\n",
    "        weights = f'{path}/resnet34_imagenet_1000_no_top.h5'\n",
    "    else:\n",
    "        raise AttributeError('mode parameter error')\n",
    "    with STRATEGY.scope():\n",
    "        if loss_type == 'bce_dice': \n",
    "            loss = bce_dice_loss\n",
    "        elif loss_type == 'bce_jaccard_loss':\n",
    "            loss = bce_jaccard_loss\n",
    "        else:\n",
    "            raise AttributeError('loss mode parameter error')\n",
    "        if umodel == 'unet':\n",
    "            model = Unet(backbone_name=backbone, encoder_weights=weights,\n",
    "                         input_shape=input_shape,\n",
    "                         classes=classes, activation='sigmoid')\n",
    "        elif umodel == 'fpn':\n",
    "            model = FPN(backbone_name=backbone, encoder_weights=weights,\n",
    "                        input_shape=input_shape,\n",
    "                        classes=classes, activation='sigmoid')\n",
    "        elif umodel == 'link':\n",
    "            model = Linknet(backbone_name=backbone, encoder_weights=weights,\n",
    "                            input_shape=input_shape,\n",
    "                            classes=classes, activation='sigmoid')\n",
    "        else:\n",
    "            raise AttributeError('umodel mode parameter error')\n",
    "        model.compile(\n",
    "            optimizer=tfa.optimizers.Lookahead(\n",
    "                tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            ),\n",
    "            loss=loss, \n",
    "            metrics=[dice_coef]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(shape, window=256, min_overlap=32):\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx, ny, 4), dtype=np.int64) \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i, j] = x1[i], x2[i], y1[j], y2[j]    \n",
    "    return slices.reshape(nx * ny, 4)\n",
    "\n",
    "def flip(img, axis=0):\n",
    "    if axis == 1:\n",
    "        return img[::-1, :, ]\n",
    "    elif axis == 2:\n",
    "        return img[:, ::-1, ]\n",
    "    elif axis == 3:\n",
    "        return img[::-1, ::-1, ]\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = [x for x in os.listdir(SUB_PATH) if '.tiff' in x]\n",
    "print('images idxs:', img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_chk(img, size):\n",
    "    sat_th = 40\n",
    "    pix_th = 200 * size // 256\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    if (s > sat_th).sum() <= pix_th or img.sum() <= pix_th: \n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = {}\n",
    "for i_img, img_file in enumerate(img_files):\n",
    "    print('-' * 20, img_file, '-' * 20)\n",
    "    img_data = rasterio.open(os.path.join(SUB_PATH, img_file), transform=IDNT)\n",
    "    print('img shape:', img_data.shape)\n",
    "    if img_data.count != 3:\n",
    "        print('img file with subdatasets as channels')\n",
    "        layers = [rasterio.open(subd) for subd in img_data.subdatasets]\n",
    "    img_preds = np.zeros(img_data.shape, dtype=np.uint8)\n",
    "    tile_size = int(params['img_size'] * EXPAND)\n",
    "    tile_resized = int(tile_size * params['resize'])\n",
    "    slices = make_grid(\n",
    "        img_data.shape, \n",
    "        window=tile_resized, \n",
    "        min_overlap=MIN_OVERLAP\n",
    "    )\n",
    "    models = []\n",
    "    for ver, folds in MDLS_FOLDS.items():\n",
    "        for n_fold in folds:\n",
    "            checkpoint_path = f'{MDLS_PATHS[ver]}/model_{n_fold}.hdf5'\n",
    "            model = get_model(\n",
    "                params_dict[ver]['backbone'], \n",
    "                input_shape=(tile_size, tile_size, 3),\n",
    "                path=MDLS_PATHS[ver],\n",
    "                loss_type=params_dict[ver]['loss'],\n",
    "                umodel=params_dict[ver]['umodel']\n",
    "            )\n",
    "            model.load_weights(checkpoint_path)\n",
    "            models.append(model)\n",
    "            print('ver:', ver, '| model loaded:', checkpoint_path)\n",
    "    empty_count, full_count = 0, 0\n",
    "    for (x1, x2, y1, y2) in tqdm(slices, desc=f'{img_file}'):\n",
    "        if img_data.count == 3: # normal\n",
    "            img = img_data.read(\n",
    "                [1, 2, 3], \n",
    "                window=Window.from_slices((x1, x2), (y1, y2))\n",
    "            )\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else: # with subdatasets/layers\n",
    "            img = np.zeros((tile_resized, tile_resized, 3), dtype=np.uint8)\n",
    "            for fl in range(3):\n",
    "                img[:, :, fl] = layers[fl].read(\n",
    "                    window=Window.from_slices((x1, x2), (y1, y2))\n",
    "                )\n",
    "        if hsv_chk(img, tile_resized):\n",
    "            img = cv2.resize(img, (tile_size, tile_size))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            pred = np.zeros((tile_size, tile_size), dtype=np.float32)\n",
    "            for tta_mode in TTAS:\n",
    "                img_aug = flip(img, axis=tta_mode)\n",
    "                img_aug = np.expand_dims(img_aug, 0)\n",
    "                img_aug = img_aug.astype(np.float32) / 255\n",
    "                for model in models:\n",
    "                    pred_aug = np.squeeze(model.predict(img_aug))\n",
    "                    pred += flip(pred_aug, axis=tta_mode) ** .5\n",
    "            pred /= (len(models) * len(TTAS))\n",
    "            pred = cv2.resize(pred, (tile_resized, tile_resized))\n",
    "            img_preds[x1:x2, y1:y2] = img_preds[x1:x2, y1:y2] + \\\n",
    "                (pred > THRESHOLD).astype(np.uint8)\n",
    "        else:\n",
    "            img_preds[x1:x2, y1:y2] = 0\n",
    "            empty_count += 1\n",
    "        full_count += 1\n",
    "    del model, models, img, pred, img_aug, pred_aug; gc.collect()\n",
    "    print('img max:', np.max(img_preds), '| voters:', VOTERS)\n",
    "    print('empty tiles', empty_count, 'of total', full_count)\n",
    "    img_preds = (img_preds >= VOTERS).astype(np.uint8)\n",
    "    rle_pred = rle_encode_less_memory(img_preds)\n",
    "    subm[i_img] = {'id':img_file.replace('.tiff', ''), 'predicted': rle_pred}\n",
    "    del img_preds, img_data, rle_pred; gc.collect()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(subm).T\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    df_masks = pd.read_csv(f'{DATA_PATH}/train.csv').set_index('id')\n",
    "    idx = df_sub.iloc[0].id\n",
    "    img = tiff.imread(os.path.join(SUB_PATH, idx + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    msk_p = enc2mask([df_sub.iloc[0].predicted], (img.shape[1], img.shape[0]))\n",
    "    msk = enc2mask([df_masks.loc[idx, 'encoding']], (img.shape[1], img.shape[0]))\n",
    "    print(img.shape)\n",
    "    print(msk_p.shape)\n",
    "    print(msk.shape)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk_p, alpha=.6)\n",
    "    plt.imshow(msk, alpha=.3)\n",
    "    plt.title(idx)\n",
    "    plt.show()\n",
    "else:\n",
    "    idx = df_sub.iloc[0].id\n",
    "    img = tiff.imread(os.path.join(SUB_PATH, idx + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    msk_p = enc2mask([df_sub.iloc[0].predicted], (img.shape[1], img.shape[0]))\n",
    "    print(img.shape)\n",
    "    print(msk_p.shape)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk_p, alpha=.4)\n",
    "    plt.title(idx)\n",
    "    plt.show()\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
